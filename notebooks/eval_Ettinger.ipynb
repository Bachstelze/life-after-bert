{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac3a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datasets import interleave_datasets, load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from life_after_bert import evaluate_encoder, MCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116b2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"roberta-large\"\n",
    "task_type = \"oLMpics MLM\"\n",
    "num_choices = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f251f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377ef113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:47:56 | WARNING | datasets.builder | Reusing dataset psycholinguistic_eval_dataset (/home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/CPRAG/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e379d582f5041f1992399c772c36f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:47:56 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/CPRAG/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168/cache-49b186ef2cd1b063.arrow\n",
      "2022-04-15 15:47:56 | WARNING | data.py | Truncated 13 tokens from answer choices.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"KevinZ/psycholinguistic_eval\", \"CPRAG\")[\"test\"]\n",
    "\n",
    "def preprocess_CPRAG(example):\n",
    "    question = f'{example[\"context_s1\"]} {example[\"context_s2\"]} [MASK]'\n",
    "    choices = [example[key] for key in [\"expected\", \"within_category\", \"between_category\"]]\n",
    "    random.shuffle(choices)\n",
    "    answer_id = choices.index(example[\"expected\"])\n",
    "\n",
    "    return {\n",
    "        \"questions\": question,\n",
    "        \"choices\": choices,\n",
    "        \"answer_ids\": answer_id,\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(preprocess_CPRAG)\n",
    "dataset = MCDataset(dataset[\"questions\"], dataset[\"choices\"], dataset[\"answer_ids\"], num_choices, task_type, tokenizer, max_length=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e43511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c488dfd24034d39b4f95559a721738b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CPRAG Sensitivity: 0.8529411764705882'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity, (all_answers, all_preds, all_top_preds) = evaluate_encoder(model, tokenizer, dataset, device=device, output_topk=5)\n",
    "f\"CPRAG Sensitivity: {sensitivity}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6404f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPRAG Top 5 Accuracy: 0.6470588235294118'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "tokenized_answers = torch.stack(dataset.choice_ids).gather(1, dataset.answer_ids.unsqueeze(1))\n",
    "\n",
    "for i, tokenized_answer in enumerate(tokenized_answers):\n",
    "    num_correct += 1 if tokenized_answer in all_top_preds[i] else 0\n",
    "    \n",
    "f\"CPRAG Top 5 Accuracy: {num_correct / len(tokenized_answers)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51db2bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:48:01 | WARNING | datasets.builder | Reusing dataset psycholinguistic_eval_dataset (/home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/ROLE/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca7b3c54e314043b45b88c869990ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:48:01 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/ROLE/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168/cache-50225d784b191933.arrow\n",
      "2022-04-15 15:48:01 | WARNING | data.py | Truncated 9 tokens from answer choices.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"KevinZ/psycholinguistic_eval\", \"ROLE\")[\"test\"]\n",
    "dataset = dataset.map(lambda ex: {\n",
    "    \"questions\": f\"{ex['context']} [MASK]\",\n",
    "    \"choices\": ex[\"expected\"].split(\"|\") + [tokenizer.mask_token] * (9 - ex[\"expected\"].count(\"|\")),\n",
    "    \"answer_ids\": 0,\n",
    "})\n",
    "\n",
    "dataset = MCDataset(dataset[\"questions\"], dataset[\"choices\"], dataset[\"answer_ids\"], 10, task_type, tokenizer, max_length=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32827d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290485340ab14146815be2012ffb6d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity, (all_answers, all_preds, all_top_preds) = evaluate_encoder(model, tokenizer, dataset, device=device, output_topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c623c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROLE Top 5 Accuracy: 0.4659090909090909'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for i, tokenized_answer_tensor in enumerate(dataset.choice_ids):\n",
    "    tokenized_answers = list(filter((tokenizer.mask_token_id).__ne__, tokenized_answer_tensor.tolist()))\n",
    "    num_correct += 1 if not set(tokenized_answer_tensor.tolist()).isdisjoint(all_top_preds[i].tolist()) else 0\n",
    "    \n",
    "f\"ROLE Top 5 Accuracy: {num_correct / len(dataset.choice_ids)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b373cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:48:56 | WARNING | datasets.builder | Reusing dataset psycholinguistic_eval_dataset (/home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/NEG-NAT/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e949674ba31b4ce1b3e2bc6ecbd928d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"KevinZ/psycholinguistic_eval\", \"NEG-NAT\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a57b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:49:00 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/NEG-NAT/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168/cache-26be8ca9aeb63254.arrow\n",
      "2022-04-15 15:49:00 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/kzhao/.cache/huggingface/datasets/KevinZ___psycholinguistic_eval_dataset/NEG-NAT/1.0.0/3eee8f93d6c1c8e5f6f89524f7b9c66b5d12596259913420a745eb81f2483168/cache-311593c865f147a3.arrow\n"
     ]
    }
   ],
   "source": [
    "def preprocess_NEGNAT_aff(example):\n",
    "    question = f'{example[\"context_aff\"]} [MASK]'\n",
    "    choices = [example[key] for key in [\"target_aff\", \"target_neg\"]]\n",
    "    random.shuffle(choices)\n",
    "    answer_id = choices.index(example[\"target_aff\"])\n",
    "\n",
    "    return {\n",
    "        \"questions\": question,\n",
    "        \"choices\": choices,\n",
    "        \"answer_ids\": answer_id,\n",
    "    }\n",
    "\n",
    "def preprocess_NEGNAT_neg(example):\n",
    "    question = f'{example[\"context_neg\"]} [MASK]'\n",
    "    choices = [example[key] for key in [\"target_aff\", \"target_neg\"]]\n",
    "    random.shuffle(choices)\n",
    "    answer_id = choices.index(example[\"target_neg\"])\n",
    "\n",
    "    return {\n",
    "        \"questions\": question,\n",
    "        \"choices\": choices,\n",
    "        \"answer_ids\": answer_id,\n",
    "    }\n",
    "\n",
    "dataset = interleave_datasets([dataset.map(preprocess_NEGNAT_aff), dataset.map(preprocess_NEGNAT_neg)])\n",
    "dataset = MCDataset(dataset[\"questions\"], dataset[\"choices\"], dataset[\"answer_ids\"], num_choices, task_type, tokenizer, max_length=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98fab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4e696d2bd0423aabe2e6723687e312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NEG-NAT Sensitivity: 0.65625'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity, (all_answers, all_preds, all_top_preds) = evaluate_encoder(model, tokenizer, dataset, device=device, output_topk=5)\n",
    "f\"NEG-NAT Sensitivity: {sensitivity}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c16b8591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEG-NAT Top 5 Accuracy: 0.46875'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "tokenized_answers = torch.stack(dataset.choice_ids).gather(1, dataset.answer_ids.unsqueeze(1))\n",
    "\n",
    "for i, tokenized_answer in enumerate(tokenized_answers):\n",
    "    num_correct += 1 if tokenized_answer in all_top_preds[i] else 0\n",
    "    \n",
    "f\"NEG-NAT Top 5 Accuracy: {num_correct / len(tokenized_answers)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9268b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
