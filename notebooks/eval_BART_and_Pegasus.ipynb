{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from life_after_bert import LaBEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(\"facebook/bart-large\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:42 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_age_comparison_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395668cabd4040de9522de8dfb2259b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:47 | INFO | eval.py | Accuracy on Age Comparison: 0.862\n",
      "2022-04-21 11:54:47 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_always_never_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01c0dbaaeb540d1bdde2952e302544a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:48 | INFO | eval.py | Accuracy on Always Never: 0.14285714285714285\n",
      "2022-04-21 11:54:48 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_antonym_negation_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041b55bf11f147f997f346e09c5d1815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:50 | INFO | eval.py | Accuracy on Antonym Negation: 0.538\n",
      "2022-04-21 11:54:50 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_multihop_composition_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe460115b7bd4b81b76fa3eea0fc2fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:52 | INFO | eval.py | Accuracy on Multihop Composition: 0.338\n",
      "2022-04-21 11:54:52 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_size_comparison_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed29213fcbcd4fe38a9572d0f1bbc2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:54 | INFO | eval.py | Accuracy on Size Comparison: 0.508\n",
      "2022-04-21 11:54:54 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_taxonomy_conjunction_dev.jsonl\n",
      "2022-04-21 11:54:54 | WARNING | data.py | Truncated 71 tokens from answer choices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0fcc30c082422a8aacc2bd500ee20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:54:56 | INFO | eval.py | Accuracy on Taxonomy Conjunction: 0.4257095158597663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Age Comparison': 0.862,\n",
       " 'Always Never': 0.14285714285714285,\n",
       " 'Antonym Negation': 0.538,\n",
       " 'Multihop Composition': 0.338,\n",
       " 'Size Comparison': 0.508,\n",
       " 'Taxonomy Conjunction': 0.4257095158597663}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_infos = [\n",
    "    (\"Age Comparison\", 2), \n",
    "    (\"Always Never\", 5), \n",
    "    (\"Antonym Negation\", 2), \n",
    "    (\"Multihop Composition\", 3), \n",
    "    (\"Size Comparison\", 2),\n",
    "    (\"Taxonomy Conjunction\", 3)\n",
    "]\n",
    "\n",
    "evaluator = LaBEvaluator()\n",
    "task_accs = evaluator.evaluate(model, tokenizer, task_infos, model_arch=\"encoder\", device=device)\n",
    "task_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:05 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_age_comparison_dev.jsonl\n",
      "2022-04-21 11:55:06 | WARNING | eval.py | Assuming T5.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f831939a9d6f4cd1971c6fbbedd04dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:08 | INFO | eval.py | Accuracy on Age Comparison: 0.506\n",
      "2022-04-21 11:55:08 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_always_never_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f77dfb9b58044e3b77c47eb56e7a8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:09 | INFO | eval.py | Accuracy on Always Never: 0.25357142857142856\n",
      "2022-04-21 11:55:09 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_antonym_negation_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95b3046b26549d78510e30d81e53d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:10 | INFO | eval.py | Accuracy on Antonym Negation: 0.498\n",
      "2022-04-21 11:55:10 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_multihop_composition_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899ac4fffd3d4a05a8093c1c93d3491c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:12 | INFO | eval.py | Accuracy on Multihop Composition: 0.338\n",
      "2022-04-21 11:55:12 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_size_comparison_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69987af458f64d1a81090fc3581a4315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:14 | INFO | eval.py | Accuracy on Size Comparison: 0.506\n",
      "2022-04-21 11:55:14 | INFO | data.py | Loading jsonl file from /home/kzhao/life-after-bert/tests/data/oLMpics_taxonomy_conjunction_dev.jsonl\n",
      "2022-04-21 11:55:14 | WARNING | data.py | Truncated 10 tokens from answer choices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94c0bc407fb437eb688158825d7e187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 11:55:16 | INFO | eval.py | Accuracy on Taxonomy Conjunction: 0.3572621035058431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Age Comparison': 0.506,\n",
       " 'Always Never': 0.25357142857142856,\n",
       " 'Antonym Negation': 0.498,\n",
       " 'Multihop Composition': 0.338,\n",
       " 'Size Comparison': 0.506,\n",
       " 'Taxonomy Conjunction': 0.3572621035058431}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-large\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/pegasus-large\")\n",
    "task_accs = evaluator.evaluate(model, tokenizer, task_infos, model_arch=\"encoder-decoder\", device=device)\n",
    "task_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
